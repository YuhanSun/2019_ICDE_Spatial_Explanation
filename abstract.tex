\begin{abstract}
%In the last few years, there has been a tremendous increase in the use of big data. Most of this data is hard to understand because of its size and dimensions. The importance of this problem can be emphasized by the fact that Big Data Research and Development Initiative was announced by the United States administration in 2012 to address problems faced by the government. Various states and cities in the US gather spatial data about incidents like police calls for service.

When a data scientist analyzes mobility data (e.g., using a data visualization tool), she may find out some interesting facts in the dataset. An example of a {\fact} can be: ``The number of Taxi trips in NYC on January 23, 2016, dropped drastically as compared to other days of the same month". However, the data scientist may be left clueless if they cannot find a crisp {\explanation} to such a {\fact}. Furthermore, the tedious task of finding an {\explanation} by manually scraping the data becomes even impossible with big data. 
%In this paper, we present an automated framework which guides the data scientist to find spatial {\explanation}s for {\fact}s discovered on spatial data. The proposed framework formally represents a {\fact} as an arithmetic relationship between queries posted on the data. 
%The proposed framework introduces a taxonomy of Observation/Explanation 
Existing techniques are designed for non-spatial data which cannot be applied to spatial data because it does not consider the spatial proximity. In this paper, we propose an automatic framework which guides the data scientist to explain the {\fact} discovered from mobility data. Our approach expands the aggravation and intervention techniques while using spatial partitioning/clustering to improve {\explanation}s for spatial data. Experiments show that the proposed approach outperforms the state-of-the-art approaches in finding the {\explanation} for {\fact}s extracted from NYC taxi real mobility dataset.
% in precision and recall while outperforming intervention in precision when finding explanations for observations made on a real NYC taxi dataset as well as a disease outbreak datasets.
%, there are a lot of differences. How can we explain what factors account for these differences? 
%If we define the observation as an arithmetic relationship between queries, 
%this kind of problem can be solved by aggravation or intervention. Aggravation views the value of our observation for different set of tuples while intervention looks at the value of the observation after removing sets of tuples. We call the predicates which represent these tuples, explanations. Observations by themselves have limited importance. For example, if we observe a large number of taxi trips in a specific area, we might ask the question: Why are there so many trips here? Explanations attempt to answer these kinds of questions.

%While aggravation and intervention are designed for non spatial data, we propose a new approach for explaining spatially heterogeneous data. Our approach expands on aggravation and intervention while using spatial partitioning/clustering to improve explanations for spatial data. Our proposed approach was evaluated against a real-world taxi dataset as well as a synthetic disease outbreak datasets. The approach was found to outperform aggravation in precision and recall while outperforming intervention in precision.
\end{abstract}
