\section{CONCLUSION AND FUTURE WORK}
\label{chp:concl}
In this paper, we studied different approaches to spatial {\explanation}s for arbitrary observations. We built an approach called {\solution}. According to our evaluation, our approach outperforms {\aggravation} and {\intervention} in precision while it outperforms {\aggravation} in recall.From a data analyst perspective, it is designed to provide an advantage over traditional data analytics using relational database systems. The reason is that we use programming paradigms for distributed processing. Even though our implementation is designed to work on Apache Spark, the paradigms used may be useful for future distributed processing systems like GOLEM which has an even larger processing scope \cite{golem2018}. In addition to saving valuable time for a data analyst, our system is also useful for reducing the scope of work for the analyst. The proposed system can be used as a search engine like Google where the analyst can search by using observations instead of search terms and the system comes up with {\explanation}s instead of web pages. Instead of looking at the entire data, the analyst can look at a small subset represented by these {\explanation}s to find what they are looking for.

There are a number of improvements that can be made on top of our proposed approach. One interesting idea is to use influence and intensity as parameters of perceptrons in a neural network \cite{grossberg1988nonlinear,widrow199030}. The neural network can be trained to explain specific datasets by using ground truth.
Many spatial datasets that we find also have a temporal component. An improvement can be made to use the time range as a secondary citizen of our candidate {\explanation}s. We can build a temporal hierarchy in the same way we build a spatial hierarchy. The spatiotemporal hierarchy can be represented as a pyramid instead of a tree.
If we extend our idea of the spatiotemporal system to a neural network, we can think of it from the perspective of a recurrent neural network\cite{chung2016hierarchical}. It might also help to use Long Short Term Memory(LSTM) model to encapsulate the value of {\explanation}s at levels of the hierarchy which are far apart \cite{hochreiter1997long}.
Since influence and intensity are expensive operations, the time complexity of the network should also be taken into account and heuristics should be used where necessary when using approaches with a lot of inputs.

